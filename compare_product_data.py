# -*- coding: utf-8 -*-
"""compare_product_data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xSbK_RM2_6SbVp_SnbMeOykL4S6ie7Wy
"""

!pip install selenium
!apt-get update # to update ubuntu to correctly run apt install
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin
import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd

def Daraz_Scraper(query):
    #Open File
    file = pd.read_csv('/content/data/daraz-all.csv')

    #Declare Data
    price = 999999999999
    product_Data = []
    
    #Loop throw file
    for index, row in file.iterrows():
        #check wather query is present or not
        if query in str(row['products-name']):  b 
            try:
                chrome_options = webdriver.ChromeOptions()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
                #initialize chrome web driver
                #driver = webdriver.Chrome(ChromeDriverManager().install())

                #maximize browser
                #driver.maximize_window()

                #scrap site data
                driver.get(row['products-link-href'])
                driver.implicitly_wait(3)

                #scrap price
                product_price = driver.find_element(By.CLASS_NAME, 'pdp-price').text
                product_price = product_price[2:] #onno site er belay eita baad jabe
                product_price = int(product_price)
                
                # check and set product data for lower priced product
                if(product_price<price):
                    price = product_price
                    product_title = driver.find_element(By.CLASS_NAME, 'pdp-mod-product-badge-title').text
                    product_url = row['products-link-href']
                    product_image_url = driver.find_element(By.TAG_NAME, 'img').get_attribute("src")

                    product_Data = [product_title, price, product_url, product_image_url]
                    
                #terminate webdriver
                driver.quit()
            except:
                pass
    
    return product_Data

def Banglarshopers_Scraper(query):
    #Open File
    file = pd.read_csv('/content/data/banglashoppers.csv')

    #Declare Data
    price = 999999999999
    product_Data = []
    
    #Loop throw file
    for index, row in file.iterrows():
        #check wather query is present or not
        if query in str(row['products-name']):
            try:
                chrome_options = webdriver.ChromeOptions()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
                #initialize chrome web driver
                #driver = webdriver.Chrome(ChromeDriverManager().install())

                #maximize browser
                #driver.maximize_window()

                #scrap site data
                driver.get(row['products-link-href'])
                driver.implicitly_wait(3)

                #scrap price
                product_price = driver.find_element(By.CLASS_NAME, 'price').text
                product_price = product_price[2:] #onno site er belay eita baad jabe
                product_price = int(product_price)
                
                # check and set product data for lower priced product
                if(product_price<price):
                    price = product_price
                    product_title = driver.find_element(By.CLASS_NAME, 'base').text
                    product_url = row['products-link-href']
                    product_image_url = driver.find_element(By.TAG_NAME, 'img').get_attribute("src")

                    product_Data = [product_title, price, product_url, product_image_url]
                    
                #terminate webdriver
                driver.quit()
            except:
                pass
    
    return product_Data

def Jadroo_Scraper(query):
    #Open File
    file = pd.read_csv('/content/data/jadroo-all.csv')

    #Declare Data
    price = 999999999999
    product_Data = []
    
    #Loop throw file
    for index, row in file.iterrows():
        #check wather query is present or not
        if query in str(row['products-name']):
            try:
                chrome_options = webdriver.ChromeOptions()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
                #initialize chrome web driver
                #driver = webdriver.Chrome(ChromeDriverManager().install())

                #maximize browser
                #driver.maximize_window()

                #scrap site data
                driver.get(row['products-link-href'])
                driver.implicitly_wait(3)

                #scrap price
                product_price = driver.find_element(By.CLASS_NAME, 'product-price').text
                product_price = product_price[2:] #onno site er belay eita baad jabe
                product_price = int(product_price)
                
                # check and set product data for lower priced product
                if(product_price<price):
                    price = product_price
                    product_title = driver.find_element(By.CLASS_NAME, 'product-name').text
                    product_url = row['products-link-href']
                    product_image_url = driver.find_element(By.TAG_NAME, 'img').get_attribute("src")

                    product_Data = [product_title, price, product_url, product_image_url]
                    
                #terminate webdriver
                driver.quit()
            except:
                pass
    
    return product_Data

def Othoba_Scraper(query):
      #Open File
      file = pd.read_csv('/content/data/othoba-all.csv')

      #Declare Data
      price = 999999999999
      product_Data = []
    
      #Loop throw file
      for index, row in file.iterrows():
        #check wather query is present or not
        if query in str(row['products-name']):
            try:
                chrome_options = webdriver.ChromeOptions()
                chrome_options.add_argument('--headless')
                chrome_options.add_argument('--no-sandbox')
                chrome_options.add_argument('--disable-dev-shm-usage')
                driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
                #initialize chrome web driver
                #driver = webdriver.Chrome(ChromeDriverManager().install())

                #maximize browser
                #driver.maximize_window()

                #scrap site data
                driver.get(row['products-link-href'])
                driver.implicitly_wait(3)

                #scrap price
                product_price = driver.find_element(By.CLASS_NAME, 'product-price').text
                product_price = product_price[2:] #onno site er belay eita baad jabe
                product_price = int(product_price)
                
                # check and set product data for lower priced product
                if(product_price<price):
                    price = product_price
                    product_title = driver.find_element(By.CLASS_NAME, 'product-name').text
                    product_url = row['products-link-href']
                    product_image_url = driver.find_element(By.TAG_NAME, 'img').get_attribute("src")

                    product_Data = [product_title, price, product_url, product_image_url]
                    
                #terminate webdriver
                driver.quit()
            except:
                pass
    
      return product_Data

qry = input('Enter Product Name: ')
product_Data_Daraz = Daraz_Scraper(qry)
product_Data_Banglarshopers = Banglarshopers_Scraper(qry)
product_data_Jadroo = Jadroo_Scraper(qry)
product_data_Othoba = Othoba_Scraper(qry)
print("Side Name: Daraz")
print("Product Name: ",product_Data_Daraz[0])
print("Product Price: ",product_Data_Daraz[1])
print("Product URL: ",product_Data_Daraz[2])
print("Product Image URL: ",product_Data_Daraz[3])

print("Side Name: Daraz")
print("Product Name: ",product_Data_Daraz[0] )
print("Product Price: ",product_Data_Daraz[1] )
print("Product URL: ",product_Data_Daraz[2] )
print("Product Image URL: ",product_Data_Daraz[3] )

# print(product_Data_Banglarshopers)
# print(product_data_Jadroo)

print("Side Name: Jadroo")
print(product_data_Jadroo)
# print("Product Name: ",product_data_Jadroo[0])
# print("Product Price: ",product_data_Jadroo[1])
# print("Product URL: ",product_data_Jadroo[2])
# print("Product Image URL: ",product_data_Jadroo[3])